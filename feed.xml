<?xml version="1.0" encoding="utf-8" ?>
<rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:wfw="http://wellformedweb.org/CommentAPI/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>John Detlefs' Web Log</title>
    <atom:link href="/feed.xml" rel="self" type="application/rss+xml"></atom:link>
    <link></link>
    <description>a blog for my coding adventures</description>
    <pubDate>Sun, 12 Jun 2016 17:00:00 -0700</pubDate>
    <generator>Wintersmith - https://github.com/jnordberg/wintersmith</generator>
    <language>en</language>
    <item>
      <title>Dimension Reduction, a review of a review</title>
      <link>/articles/dim_reduction/</link>
      <pubDate>Sun, 12 Jun 2016 17:00:00 -0700</pubDate>
      <guid isPermaLink="true">/articles/dim_reduction/</guid>
      <author></author>
      <description>&lt;script type=&quot;text/x-mathjax-config&quot;&gt;
MathJax.Hub.Config({
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
});
&lt;/script&gt;
&lt;script type=&quot;text/javascript&quot; async
  src=&quot;https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML&quot;&gt;
&lt;/script&gt;

&lt;p&gt;Hello! This is my first post moving over to a new site built by
&lt;a href=&quot;https://github.com/jnordberg/wintersmith&quot;&gt;wintersmith&lt;/a&gt;. Originally I was going
to use jekyll pages, but there was an issue with the latest ruby version not being
available for Linux, (maybe macs are better…). I spent &lt;em&gt;way too much&lt;/em&gt; time
figuring out how to install a markdown plugin that allowed for the inclusion of
Latex. I did this all without realizing I could simply include:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;lt;script type=&amp;quot;text/javascript&amp;quot; async
  src=&amp;quot;https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML&amp;quot;&amp;gt;
&amp;lt;/script&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;below my article title and latex would easily render. Now that this roadblock is
cleared, I have no excuses preventing me from writing a post about my work.  &lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;This post is meant to discuss various dimension reduction methods
as a preface to a more in-depth post about diffusion maps
performed on molecular dynamics simulation trajectories. It assumes college-level math skills, but
will try to briefly explain high-level concepts from Math and Stats.
Towards the end I will provide a segue into the next post.&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Dimensionality_reduction&quot;&gt;Dimension reduction&lt;/a&gt;
is performed on a data matrix $ X $ consisting of $n$ ‘samples’ wherein
each sample has a set of $m$ ‘features’ associated with it. The data in the matrix
is considered to have dimension $m$, but oftentimes the actual ‘intrinsic dimensionality’
is much lower. As Laurens van der Maaten &lt;a href=&quot;https://www.tilburguniversity.edu/upload/59afb3b8-21a5-4c78-8eb3-6510597382db_TR2009005.pdf&quot;&gt;defines it&lt;/a&gt;, ‘intrinsic dimensionality’
is ‘the the minimum number of parameters needed to account for the observed properties of the data’.&lt;/p&gt;
&lt;p&gt;(So far, the most didactic explanation of this fact was presented
in a paper on diffusion maps by &lt;a href=&quot;http://dip.sun.ac.za/~herbst/research/publications/diff_maps_prasa2008.pdf&quot;&gt;Porte et al&lt;/a&gt;.
In the paper, a dataset of m-by-n pixel pictures of a simple image randomly rotated
originally has dimension $mn$ but after dimension reduction, the dataset can be
organized two dimensionally based on angle-of rotation.)&lt;/p&gt;
&lt;p&gt;At the most abstract level, dimension reduction methods usually are posed as an
optimization problem that ultimately requires the solution to an eigenvalue problem.
What is an &lt;a href=&quot;https://en.wikipedia.org/wiki/Optimization_problem&quot;&gt;optimization problem&lt;/a&gt; you ask?
That wikipedia article should help some, the optimization being done in dimension
reduction is finding some linear or non-linear relation $ M $ that minmizes (or maximizes)
a cost function $ \phi (x) $ on some manipulation of the data matrix, call it $ X_{manipulated} $.
Examples of various functions will be given in detail later.&lt;/p&gt;
&lt;p&gt;In most cases this can be turned into an eigenproblem posed as:
$$ X_{manipulated} M = \lambda M $$&lt;/p&gt;
&lt;p&gt;Solving this equation using some algorithm like Singular Value Decomposition
or Symmetric Eigenvalue Decomposition will provide a set of m linearly-independent
eigenvectors that act as a basis for a lower dimensional space.
(Linear independence means no vector in the set can be expressed as
some sum of the others, a basis set has the property that any vector in a space
can be written as the sum of vectors in the set.) The set of eigenvectors is of
given by an eigenvalue decomposition will be the ‘spectrum’ of the matrix $M$.
This spectrum will have what is referred to as a ‘spectral gap’ after a certain number
of eigenvalues. After these $k$ eigenvalues, the value of all subsequent eigenvalues
is much smaller than all those before them. The number of significant eigenvalues before this
first diminished value reflects the intrinsic dimension $k$ of a space.&lt;/p&gt;
&lt;p&gt;In some cases, the manipulation is somewhat more complicated, and creates what
is called a &lt;a href=&quot;https://en.wikipedia.org/wiki/Eigendecomposition_of_a_matrix#Generalized_eigenvalue_problem&quot;&gt;&lt;em&gt;generalized eigenvalue problem&lt;/em&gt;&lt;/a&gt;.
In these situations the problem posed is $$ X_a M = \lambda X_b M $$
Where $X_a$ and $X_b$ are distinct but both still generated from some manipulation
on the original data matrix X.&lt;/p&gt;
&lt;p&gt;The methods discussed so far necessitate the use of convex cost functions for
an optimization. In set theory, convexity indicates that a set contains its subsets.
An open interval $ (a,b) $ is convex whereas the open interval missing a point is not.
Convex functions are similar but not entirely related, a convex function does not
have any &lt;em&gt;local optima&lt;/em&gt; which means that if you’re at a maximum or minimum, you know it is global.&lt;/p&gt;
&lt;p&gt;(I think there is a reason why people in optimization refer to surfaces as landscapes.
An interesting surface may have many hills and valleys, and finding an optimal path
is like a hiker trying to cross a mountain path blind — potentially problematic.)&lt;/p&gt;
&lt;p&gt;Convex functions will always achieve the same solution given some input parameters,
but non-convex functions may get stuck on some local optima. This is why a method
like &lt;a href=&quot;https://lvdmaaten.github.io/publications/papers/JMLR_2008.pdf&quot;&gt;t-SNE&lt;/a&gt; will converge to different results on different iterations.&lt;/p&gt;
&lt;p&gt;Methods for dimension reduction will be either linear or non-linear mappings.
In both cases, the original data matrix $X$ is embeddable in some manifold. A manifold
is any surface that is &lt;a href=&quot;http://planetmath.org/locallyhomeomorphic&quot;&gt;locally homeomorphic&lt;/a&gt; to $R^{2}$.
We want these mappings to preserve both the local structure of the manifold, while also
preserving the global structure. I think the notion of structure is left specifically
vague in literature because it is just so damn weird (it is really hard to think about
things in greater than 3 dimensions…)&lt;/p&gt;
&lt;p&gt;A great example of data embeddable in a weird manifold, albeit three dimensional manifold is the swiss roll:
&lt;img src=&quot;/articles/dim_reduction/swissroll.gif&quot; alt=&quot;swiss roll&quot;&gt; borrowed from &lt;a href=&quot;http://people.cs.uchicago.edu/~dinoj/manifold/swissroll.html&quot;&gt;dinoj&lt;/a&gt;.
The many different dimension reduction methods available will have disparate
results when performed on this data. When restricted to paths along the manifold,
red data will be far apart from black, but if a simple euclidean distance is measured,
the points might be considered close. A dimension map that uses simple euclidean
distance between points to resolve structure will fail miserably to eek out the
swiss roll embedding.&lt;/p&gt;
&lt;p&gt;When looking to investigate the lower dimensional space created by a dimension
reduction, linear mappings have an explicit projection provided by the matrix formed
by the eigenvectors. Non-linear methods do not have such an explicit relationship.
Finding physical meaning from the order parameters given by a non-linear technique
is an active area of research.&lt;/p&gt;
&lt;p&gt;It might be too small of detail for some, but the rest of this post will be
focused on providing a quick explanation of various dimension reduction techniques.
The general format will be:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;optimization problem posed&lt;/li&gt;
&lt;li&gt;formal eigenvalue problem given&lt;/li&gt;
&lt;li&gt;interesting insights and relations&lt;/li&gt;
&lt;li&gt;pictures that I like from other work  &lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;multidimensional-scaling-mds-classical-scaling-pca&quot;&gt;Multidimensional Scaling (MDS), Classical Scaling, PCA&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;PCA cost function: Maximizes $Trace(M^{T}cov(X)M)$&lt;/li&gt;
&lt;li&gt;PCA eigenvalue problem $ Mv = \lambda v $ where M is this linear mapping minimizing
the covariance&lt;/li&gt;
&lt;li&gt;Classical scaling relies on the number of datapoints not the dimensionality.&lt;/li&gt;
&lt;li&gt;Classical scaling cost function: Minimizes $$ \phi ( Y ) = $ \Sigma ij =  ( d{ij} - || y{i} - y{j} ||^{2} ) $$
this is referred to as a strain cost function. (subscripts are currently an issue…)&lt;/li&gt;
&lt;li&gt;Other MDS methods can use stress or squared stress cost functions&lt;/li&gt;
&lt;li&gt;Classical scaling gives the exact same solution as PCA&lt;/li&gt;
&lt;li&gt;PCA applied to image data gives this &lt;em&gt;awesome&lt;/em&gt; term eigenfaces, an example
of which can be found below:
&lt;img src=&quot;/articles/dim_reduction/Eigenface.jpg&quot; alt=&quot;eigenfaces&quot;&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;isomap&quot;&gt;Isomap&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Geodesic distances are computed by constructing a nearest-neighbor graph and
using &lt;a href=&quot;https://www.youtube.com/watch?v=2E7MmKv0Y24&quot;&gt;Djistrka’s algorithm&lt;/a&gt; to find short distance. Erroneous connections
can be made by improperly connecting neighbors.&lt;/li&gt;
&lt;li&gt;Can fail if manifold has holes.&lt;/li&gt;
&lt;li&gt;Demonstration of failure of PCA versus success of Isomap
&lt;img src=&quot;/articles/dim_reduction/isomapfail.png&quot; alt=&quot;isomap&quot;&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;kernel-pca&quot;&gt;Kernel PCA&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Does PCA on a kernel function, retains large pairwise distances even though they are measured in the feature space&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;diffusion-maps&quot;&gt;Diffusion Maps&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;The key idea behind the diffusion distance is that it is based on integrating over all paths through the graph.&lt;/li&gt;
&lt;li&gt;Isomap will possibly short circuit, but the averaging of paths in diffusion maps will prevent this from happening,
it is not one shortest distance but a collective of shortest distances.&lt;/li&gt;
&lt;li&gt;Pairs of datapoints with a high forward transition probability have a small diffusion distance&lt;/li&gt;
&lt;li&gt;Eigenvalue problem: $ P^{(t)} v = \lambda v $, where $P$ is a diffusion matrix reflecting
all possible pairwise diffusion distances between two samples&lt;/li&gt;
&lt;li&gt;Diagonalization means that we can solve the equation for t=1 and then exponentiate eigenvalues
to find time solutions for longer diffusion distances&lt;/li&gt;
&lt;li&gt;Because the graph is fully connected, the largest eigenvalue is trivial&lt;/li&gt;
&lt;li&gt;The same revelation also stems from the fact that the process is markovian, that is
the step at time t only depends on the step at time t-1, it forms a &lt;a href=&quot;https://en.wikipedia.org/wiki/Markov_chain&quot;&gt;markov chain&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Molecular dynamics processes are certainly markovian, protein folding can
be modeled as a diffusion process with &lt;a href=&quot;https://en.wikipedia.org/wiki/Root-mean-square_deviation_of_atomic_positions&quot;&gt;RMSD&lt;/a&gt; as a metric&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;locally-linear-embedding-&quot;&gt;Locally Linear Embedding:&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;LLE describes the local properties of the manifold around a datapoint x i by writing the datapoint
as a linear combination $w i$ (the so-called reconstruction weights) of its
k-nearest-neighbors $xij$.&lt;/li&gt;
&lt;li&gt;It solves a generalized eigenvalue problem, preserves local structure.&lt;/li&gt;
&lt;li&gt;Invariant to local scale, rotation, translations&lt;/li&gt;
&lt;li&gt;&lt;p&gt;This is a cool picture demonstrating power of LLE on facial/expression recognition:&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/dim_reduction/LLE.jpg&quot; alt=&quot;lle&quot;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;LLE ails when the manifold has holes&lt;/li&gt;
&lt;li&gt;In addition, LLE can collapse large portions of the data very close
together in the low-dimensional space, because the covariance constraint
on the solution is too simple&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;laplacian-eigenmaps-&quot;&gt;Laplacian Eigenmaps:&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Laplacian Eigenmaps compute a low-dimensional representation of
the data in which the distances between a datapoint and its k nearest neighbors are minimized.&lt;/li&gt;
&lt;li&gt;The ideas studied here are a part of spectral graph theory&lt;/li&gt;
&lt;li&gt;The computation of the degree matrix M and the &lt;a href=&quot;https://en.wikipedia.org/wiki/Laplacian_matrix&quot;&gt;graph laplacian&lt;/a&gt;
L of the graph W allows for formulating the minimization problem in defined above as an eigenproblem.&lt;/li&gt;
&lt;li&gt;Generalized Eigenproblem: $Lv = \lambda Mv$&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;hessian-lle-&quot;&gt;Hessian LLE:&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Minimizes curviness of the high-dimensional manifold when embedding it into
a low dimensional data representation that is &lt;a href=&quot;https://en.wikipedia.org/wiki/Isometry_(Riemannian_geometry&quot;&gt;locally isometric&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Hessian_matrix&quot;&gt;What is a Hessian?&lt;/a&gt;.
Hessian LLE uses a local hessian at every point to describe curviness.&lt;/li&gt;
&lt;li&gt;Hessian LLE shares many characteristics with Laplacian Eigenmaps:
It replaces the manifold &lt;a href=&quot;https://en.wikipedia.org/wiki/Laplacian_matrix&quot;&gt;Laplacian&lt;/a&gt; by the manifold Hessian.
‘As a result, Hessian LLE suffers from many of the same weaknesses as Laplacian Eigenmaps
and LLE.’&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;local-tangent-space-analysis-&quot;&gt;Local Tangent Space Analysis:&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;LTSA simultaneously searches for the coordinates of the low-dimensional
data representations, and for the linear mappings of the low-dimensional
datapoints to the local tangent space of the high-dimensional data.&lt;/li&gt;
&lt;li&gt;Involves applying PCA on k neighbors of x before finding local tangent space&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;non-linear-methods&quot;&gt;Non-Linear Methods&lt;/h2&gt;
&lt;hr&gt;
&lt;h2 id=&quot;sammon-mapping&quot;&gt;Sammon mapping&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Adapts classical scaling by weighting the contribution of each pair $(i, j)$
to the cost function by the inverse of their pairwise distance in the high-dimensional space d_ij&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;multilayer-autoencoder&quot;&gt;Multilayer Autoencoder&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Uses a feed forward neural network that has a hidden layer with a small
number of neurons such that the neural network is forced to learn a
lower dimensional structure&lt;/li&gt;
&lt;li&gt;This is identical to PCA if using a linear activation function! What undiscovered
algorithms will be replicated my neural nets? Will neural nets actually hurt
scientific discovery?&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;p&gt;Alright, so that’s all the gas that is in my tank for this post.
Hopefully you’ve come and understood something a little bit better than before.
In my next post, I am going to focus on diffusion maps as they pertain to
molecular dynamics simulations. Diffusion maps are really cool in that they
really are an analogue the physical nature of complex molecular systems.&lt;/p&gt;
&lt;h2 id=&quot;works-cited&quot;&gt;Works Cited&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http://www.pages.drexel.edu/~sis26/Eigenface%20Tutorial.htm&quot;&gt;Eigenfaces from Drexel&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://web.mit.edu/6.454/www/www_fall_2003/ihler/slides.pdf&quot;&gt;MIT Manifold Learning Slides&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://www.tilburguniversity.edu/upload/59afb3b8-21a5-4c78-8eb3-6510597382db_TR2009005.pdf&quot;&gt;Dimension Reduction Review&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://dip.sun.ac.za/~herbst/research/publications/diff_maps_prasa2008.pdf&quot;&gt;Diffusion Map Brief&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://web.mit.edu/6.454/www/www_fall_2003/ihler/slides.pdf&quot;&gt;MIT Slides&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://lvdmaaten.github.io/publications/papers/JMLR_2008.pdf&quot;&gt;t-SNE paper&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;/articles/dim_reduction/&quot;&gt;Clementi Diffusion&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    <item>
      <title>Things I wished I had known when I got serious about programming</title>
      <link>/articles/5_things/</link>
      <pubDate>Thu, 09 Jun 2016 12:30:00 -0700</pubDate>
      <guid isPermaLink="true">/articles/5_things/</guid>
      <author></author>
      <description>&lt;p&gt; This is my first post about actual programming! When I started doing
    computational research about three years ago, I was lazy and borderline
    incompetent. Today, the tools I have learned allow me to be equally
    lazy while being somewhat more competent. These range from simple
    lifestyle decisions to basic tech skills.
&lt;/p&gt;
&lt;h2&gt; Tip 1: Install Linux &lt;/h2&gt;
&lt;p&gt;&lt;a href='https://www.linuxmint.com/download.php'&gt;
    &lt;img src='justdoit.gif' &gt;&lt;/a&gt;
    Do yourself a favor and install
    Linux. My first install of Linux was done on my laptop, and it turns
    out that the wifi was broken until I installed the new drivers. Figuring
    out why things broke was a bit of a slog, but I eventually
    stumbled upon a great demonstration of the beauty of open source software.
    Incredibly, this &lt;a href='https://github.com/lwfinger/'&gt;
    Realtek employee&lt;/a&gt; wrote drivers for Linux on his own time! &lt;a href=
    'http://askubuntu.com/questions/318608/lenovo-yoga-13-realtek-wireless-driver/358479#358479'&gt;
    Installing&lt;/a&gt; these drivers was a bit of a rabbit’s hole, but I firmly
    believe that system administration builds character. Also, for what
    its worth the install on my desktop was painless. &lt;br&gt;
    &lt;/p&gt;
&lt;h2&gt;&lt;br&gt; Tip 2: After installing linux, learn your shell commands &lt;/h2&gt;
    &lt;h3&gt; Navigating the command line&lt;/h3&gt;
    &lt;pre&gt;&lt;code&gt;
pwd # shows where you are in the filesystem
cd # changes directory to specfied path
ls # shows existing files in path
cp # copy specified file to new filename
grep # a tool to search for regular expressions or patterns inf iles/directories
mkdir # creates a directory with a specified name in current path
chmod # changes permissions for a file
sudo # if given administrator priveleges, this allows installation
# directories if given as a prefix to a shell command
rm # deletes stuff
which (command here) # shows the path taken to binary executable of a command
    &lt;/code&gt;&lt;/pre&gt;
    &lt;p&gt; Internalizing the numerous tools at ones disposal takes some time.
        Part of me thinks that I have learned command line tools simply
        because it makes me feel like Deckard. &lt;br&gt;
        &lt;div id='images'&gt;
        &lt;img src=enhance.gif&gt;&lt;/p&gt;
        &lt;/div&gt;
    &lt;p&gt; The workflow speed up can be tremendously useful. When it
        comes to tools like git, the Github Graphic User Interfaces (GUIs)
        available to Windows are &lt;em&gt;awful&lt;/em&gt;
        in comparison and it becomes a necessity. &lt;br&gt;&lt;br&gt;

    &lt;/p&gt;
    &lt;h3&gt;How I copied these downloaded gifs to my website directory&lt;/h3&gt;
    &lt;pre&gt;&lt;code&gt;
# after downloading some files, open terminal.
# change to website directory
# for me this is:
cd github/jdetle.github.io
pwd # press enter
# i am in /home/jdetlefs/github/jdetle.github.io
# trying to copy to /home/jdetlefs/github/jdetle.github.io/images
# the filename was some arbitrary string ‘YUjaCfF’ in Downloads
# when typing a path ‘~’ is a placeholder for ‘/home/username’
cp ~/Downloads/YU # (press tab in terminal to autocomplete to filename
# YU is a unique identifier for this file, pressing tab twice will list
# all files with these characters as an identifier (DONT PRESS
# ENTER YET)
(continued) images/‘filename’.gif # press enter
# check that it exists in the appropriate path
ls images
# ‘filename.gif’ should exist in this path!
    &lt;/code&gt;&lt;/pre&gt;
    &lt;p&gt; Initially this process may take longer than dragging and dropping
        files, but it quickly becomes far faster than using a GUI. &lt;/p&gt;
    &lt;h3&gt; How I add a newly installed program to my $PATH&lt;/h3&gt;
    &lt;pre&gt;&lt;code&gt;
echo $path
export PATH=$PATH:/path/to/my/program
echo $PATH
    &lt;/code&gt;&lt;/pre&gt;
    &lt;h3&gt; How I work in virtualenvs (kind of complicated) &lt;/h3&gt;
    &lt;p&gt; First, upgrade the things! &lt;/p&gt;
    &lt;pre&gt;&lt;code&gt;
sudo apt-get upgrade
    &lt;/pre&gt;&lt;/code&gt;
        From here, things can get complicated if you have an installation
        of &lt;a href='https://www.continuum.io/downloads'&gt;Anaconda.&lt;/a&gt;
        Both &lt;a href='https://pypi.python.org/pypi/pip'&gt;pip&lt;/a&gt;
        and anaconda are package managers, and but when installing itself,
        anaconda installs pip in its own directory, and handles virtual
        environments on its own. Things can break when using both conda and
        pip because managing dependencies is ugly and awful and left for
        people with higher pain tolerances than me. Of course, one can
        use conda virtualenvs, the differences probably aren’t too significant.
        This is actually still a problem on my laptop, so I am going to
        spend this time installing pip without conda and getting virtualenvs
        to work on my laptop! (&lt;a href='https://www.youtube.com/watch?v=xdZQL04sDBU'&gt;6 and a half hours later.&lt;/a&gt;)

        … Okay so this isn’t pretty. If anaconda3 is installed, it looks like
        virtualenvwrappers won’t work because virtualenvwrapper only
        works using python2.7? (Don’t hold me to this). My solution was
        to delete anaconda3 altogether. Often times I’ve learned that
        the brute force solution works pretty well. (Somewhere in the
        distance &lt;a href=https://twitter.com/pwang&gt; Peter Wang &lt;/a&gt;
        feels a disturbance in the force.)
    &lt;pre&gt;&lt;code&gt;
rm -rf anaconda3 # CAREFUL
    &lt;/pre&gt;&lt;/code&gt;
        &lt;em&gt; Be careful with this!!!&lt;/em&gt; It recursively deletes this
        directory and all files in it and can ruin your OS install.
    &lt;pre&gt;&lt;code&gt;
sudo apt-get install python-pip python-dev python-cython python-numpy g++
sudo pip install –upgrade pip
sudo pip install virtualenvwrapper
vi ~/.bashrc
    &lt;/pre&gt;&lt;/code&gt;
        &lt;p&gt; Crap! Another thing I have to explain! vi opens Vim, a text editor
            that keeps things fast and simple. A fresh installation of
            Ubuntu 14.04 will come with Vi Improved or vim, that is a
            superset of a vi (a relic of days of yore) but has no preinstalled functionality. To
            install a working version of Vim that allows for syntax highlighting
            and easy workflow tools, do the following.
    &lt;pre&gt;&lt;code&gt;
sudo apt-get update # cant hurt
sudo apt-get install vim
# ctrl-shift-n to open a new terminal window
# vi ~/.vimrc
# (press shift+colon) i (press enter) will allow you to start inserting
# copy and paste this  with a mouse
set expandtab
set tabstop=4
set softtabstop=4
set shiftwidth=3
set autoindent
set textwidth=80
set nocompatible
set backspace=2
set smartindent
set number
set cindent
colo torte # preinstalled color schemes in /usr/share/vim/vim74/colors
syntax on
# (press shift+colon) wq (press enter) to write and quit
# x does wq simultaneously
    &lt;/pre&gt;&lt;/code&gt;
    &lt;p&gt; Here is some more info on &lt;a href='http://bullium.com/support/vim.html'&gt;Vim&lt;/a&gt;.
        Let’s get back to editing our bash shell configuration file (~/.bashrc)
    &lt;/p&gt;
    &lt;pre&gt;&lt;code&gt;
vi ~/.bashrc
# before doing anything add the path
# (shift+colon) i (enter) and line 1 should be
PATH=~/bin:$PATH
# line 2
export PATH
# line 3
source /usr/local/bin/virtualenvwrapper.sh
# (shift+colon) x (enter) and (ctrl+shift+n) to open a new terminal
    &lt;/pre&gt;&lt;/code&gt;
    &lt;p&gt; And there you go! You should have a working installation of
        the &lt;a href='http://virtualenvwrapper.readthedocs.io/en/latest/'&gt;
            virtualenvwrapper&lt;/a&gt;
        such that you are ready to use virtual
        environments when making your first pull request on your new
        Linux system!
    &lt;/p&gt;
    &lt;h3&gt;Using pip virtualenvs to work on github projects&lt;/h3&gt;
    &lt;p&gt; Let’s make a pull request for MDAnalysis using the tools we’ve
        learned! &lt;/p&gt;
    &lt;pre&gt;&lt;code&gt;
# I like having a github/ folder for my various repositories
# First, let’s clone into the repo
cd (press enter) # takes us to home user directory
mkdir github
cd github
    &lt;/pre&gt;&lt;/code&gt;
    &lt;p&gt; Before moving further, you should create a github account if you
        haven’t already and fork &lt;a href='https://github.com/MDAnalysis/mdanalysis/'&gt;
        MDAnalysis&lt;/a&gt;. This will create a clone of the repo that will
        function as your ‘origin’ repository. &lt;a href='https://github.com/MDAnalysis/mdanalysis/'&gt;
        MDAnalysis&lt;/a&gt; will be the ‘upstream’ repository that we set up
        later.
    &lt;/p&gt;
    &lt;pre&gt;&lt;code&gt;
git clone &lt;a href=&quot;https://github.com/YOURUSERNAME/mdanalysis&quot;&gt;https://github.com/YOURUSERNAME/mdanalysis&lt;/a&gt;
# this takes a little bit (289 megabytes)
mkvirtualenv MDA
workon MDA
pip install numpy cython seaborn # installs dependencies
pip install -e . # installs MDAnalysis such that changing files
# changes how packages behave when loaded for a script
    &lt;/pre&gt;&lt;/code&gt;
&lt;p&gt; From here we can start working on establishing a git workflow using branches. &lt;/p&gt;
    &lt;pre&gt;&lt;code&gt;
git remote add upstream &lt;a href=&quot;http://github.com/MDAnalysis/mdanalysis&quot;&gt;http://github.com/MDAnalysis/mdanalysis&lt;/a&gt;
git branch NEW_PULL_REQUEST
git fetch upstream #checks for updates
git checkout upstream/develop -B develop # creates develop
# branch to rebase against later and switches to it
# there might be a way to do this without checking the branch out
# but I dont know how
git checkout NEW_PULL_REQUEST # do work on this branch
    &lt;/pre&gt;&lt;/code&gt;
    &lt;p&gt; Any time you want to save the work you’ve done, you can see the
        files you’ve changed with
    &lt;/p&gt;
    &lt;pre&gt;&lt;code&gt;
git status
    &lt;/code&gt;&lt;/pre&gt;
    &lt;p&gt; Then add them to be staged for a commit that will be merged into
        the upstream develop branch if the pull request is accepted.
    &lt;pre&gt;&lt;code&gt;
git add file_name_here
# once you’ve added everything you want to include in a PR
git commit -m ‘Insert a descriptive commit message here’
    &lt;/code&gt;&lt;/pre&gt;
    &lt;p&gt; If you want to make a tiny commit, and blend it into a previous commit.
    &lt;pre&gt;&lt;code&gt;
git rebase -i HEAD~(# of commits back you want to go)
    &lt;/code&gt;&lt;/pre&gt;
    &lt;p&gt; Use vim style interactiveness to rebase commits. Changing ‘pick’
        to ‘fixup’ ‘squashes’ a commit into the previous the first pick
        commit above it without using the commit statement.
        Using squash will combine commit statments. When happy, (shift+colon)
        (ctrl+x) and pressing Y and enter will combine commits.
        If still unsatisfied you can amend the commit manually.
    &lt;/p&gt;
    &lt;pre&gt;&lt;code&gt;
git commit –amend #edit the commit
    &lt;/code&gt;&lt;/pre&gt;
    &lt;p&gt; When you’re ready to save your work to the origin directory.
    &lt;pre&gt;&lt;code&gt;
git fetch upstream
git checkout develop
# if prompted:
git pull # updates changes made
# if your command prompt makes a recursive merge, you’ve done something wrong
git checkout NEW_PULL_REQUEST
git rebase develop # rebase against develop to avoid merge conflicts
git push origin NEW_PULL_REQUEST
    &lt;/code&gt;&lt;/pre&gt;
    &lt;p&gt; Before actually making a pull requestion on github, make sure
        you didn’t break any tests, and you’ve written new tests for
        the new code you’ve written.
    &lt;pre&gt;&lt;code&gt;
cd ~/github/mdanalysis/testsuite/
pip install -e .
cd MDAnalysisTests/
./mda_nosetests (press enter)
    &lt;/pre&gt;&lt;/code&gt;
        &lt;p&gt; Hopefully that helps! There is a bevy of more rigorous work
        that’s been done on understand git branching.
        &lt;a href='http://nvie.com/posts/a-successful-git-branching-model/'&gt;
            A succesful Git branching model&lt;/a&gt; is very helpful,
        &lt;a href='https://help.github.com/categories/bootcamp/'&gt;
            reading the github helps too.&lt;/a&gt;
        &lt;a href='https://atom.io/'&gt;Atom&lt;/a&gt; is a very nice editor with
        its github integration and hackability.
        I like to use &lt;a href='jupyter.org'&gt;Jupyter&lt;/a&gt;
        as a script playground for MDAnalysis.
    &lt;h2&gt; Tip 3: Get good at googling &lt;/h2&gt;
    &lt;p&gt; &lt;img src='noidea.jpg'&gt;This tip from &lt;a href='www.freecodecamp.com'&gt;freeCodeCamp&lt;/a&gt;
        is applicable to any problem. &lt;a href='https://github.com/FreeCodeCamp/wiki/blob/master/FreeCodeCamp-Get-Help.md'&gt;
        Read-search-ask&lt;/a&gt; is a strategy that will help you learn
        indepently and boost confidence. Adding on to this advice, I have
        found that if you find the email of someone knowledgable in the area
        you are struggling in, simply by writing an email explaining your problem
        you can often find the solution on your own. If you don’t
        figure it out, then you might just impress that person with
        your detailed investigation. Even if they aren’t impressed, they’ll likely help
        you out. People in open source are generally receptive
        to people who demonstrate that they are working hard at becoming self-reliant.
        Always err on the side of not sending that email though; nobody
        likes being harassed with trivial questions.
    &lt;/p&gt;
    &lt;h2&gt; Tip 4: When working, avoid distractions, double check,
        triple check, quadruple check… &lt;/h2&gt;
        &lt;p&gt; When working on projects involving non-commercial software
            it is especially important to think of all the possible ways you could
            have screwed something up. Check your code for glaring logic
            errors and before running an intensive calculation, run a baseline
            to ensure that things work. In quantum chemistry, an example
            for this would be running a Hartree-Fock calculation with the STO-3G basis set
            before doing something that scales much slower.
            Develop scripts to ensure you are getting expected results,
            become skilled at using grep and simple regex. (&lt;a href='http://regexr.com/'&gt;Regexr&lt;/a&gt;
            is a great playground to learn regex)
            Assume that you’ve written bad code and that bugs will
            be caused by small changes to input parameters. Expect
            things to break easily. Inspect all work exhaustively.
        &lt;/p&gt;
        &lt;p&gt; When reading academic papers, print them out and read them away from a PC.
            Usually academic papers use wildly esoteric jargon. &lt;a href='http://ferguson.matse.illinois.edu/resources/5.pdf'&gt;
            This paper&lt;/a&gt; on diffusion maps (the subject of my next blog post)
            actually features a ‘jargon box’ which is just &lt;em&gt;great&lt;/em&gt;. Academic
            papers usually also assume a high level of familiarity in the
            subject material and are written for those who are skilled at
            reading papers. It is easier to dedicate the intense
            concentration required for most papers when unplugging from tech
            and using some ear plugs.
        &lt;/p&gt;
        &lt;p&gt; Finally, when communicating over email you can embrace
            one of two strategies. Either you can add a ‘sent from my iPhone’
            tag to everything, or before adding recipients,
            take a second to go get a drink of water come back and
            reread the message for errors. Unfortunately, people will
            judge you for poor grammar even if they don’t mean to. (Shoot,
            I just ended a sentence in a preposition…)
        &lt;/p&gt;
    &lt;h2&gt; Tip 5: Tackle what intimidates you &lt;/h2&gt;
        &lt;p&gt; I seriously believe that this is the number one part of
            becoming an adult and it is something I have only really
            internalized in the last year. Problems will not go away
            by avoiding them. Oftentimes I find myself building up things
            in my head as if they will be a bigger deal than they actually
            are. Figuring out how to us virtualenvs was one example of
            such a barrier that occurred recently. This occurs in my personal
            life as well and invariably the outcome is always better than
            how I imagined it would be.
        &lt;/p&gt;&lt;img src='shiacrying.gif'&gt;
        &lt;p&gt; Having trouble getting started on a project? Unfortunately Shia isn’t
            much help here.
            Segment your work into discrete chunks. If you
            have a pull request you want to make, think of all the
            possible minutia you have to work through in order to get
            things done. I like to use Google Inbox’s reminder feature
            to constantly remind myself of these things I need to get done.
            When I finish a task, I can swipe it off my todo list and
            enjoy that feeling of catharsis.
        &lt;/p&gt;
        &lt;p&gt; If you are a budding programmer, take an algorithms class
            for free &lt;a href='http://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-006-introduction-to-algorithms-fall-2011/'&gt;here&lt;/a&gt;.
            If you still aren’t busy enough, read the MDAnalysis &lt;a href='https://github.com/MDAnalysis/mdanalysis/wiki/Guide-for-Developers'&gt;Guide
            for Developers&lt;/a&gt; and start learning with help from a tight-knit
            community of open source contributors.
        &lt;/p&gt;
</description>
    </item>
    <item>
      <title>Hello World</title>
      <link>/articles/hello_world/</link>
      <pubDate>Wed, 11 May 2016 12:30:00 -0700</pubDate>
      <guid isPermaLink="true">/articles/hello_world/</guid>
      <author></author>
      <description>&lt;p&gt;Hello world! I recently was given the amazing opportunity
    to contribute to MDAnalysis, an open source Molecular Dynamics simulation
    Analysis project through the Google Summer of Code initiative. I’ve
    been encouraged to maintain a blog by those giving me this opportunity
    so I’ll start things off by explaining how I got this great summer job.
&lt;/p&gt;
&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;
&lt;p&gt;To summarize it quickly, Google sponsors a program in which college
    students apply to work on projects for open source software organizations.
    I was very lucky to have my research advisor, Dr. Ashley Ringer
    McDonald, encourage me to apply. I satisfied the first application requirement
    by learning how to use git and closing an issue on the &lt;a href=&quot;https://github.com/MDAnalysis/mdanalysis/issues&quot;&gt;MDAnalysis Github page&lt;/a&gt;.
    After that, I spent about 40 hours of concentrated effort over spring break
    studying dimensionality reduction and molecular dynamics in order to write a coherent
    application. By turning in a rough draft early I ensured the process was iterative; the contributors to
    MDAnalysis were very helpful with their critiques of my application.
&lt;/p&gt;
&lt;p&gt; After turning in my final application, the process didn’t really stop. I made
    sure to keep making pull requests and to learn more about development workflow. I have
    learned &lt;strong&gt;so&lt;/strong&gt; much about workflow and how to get over
    the dread of starting a pull request in the past few months.
&lt;/p&gt;
&lt;p&gt; And then I got the news! I had been accepted to the Google Summer of Code!
    I was and still am extremely excited. With that being said, success
    made me lazy and somewhat complacent. Recently, I have been doing the
    bare minimum in terms of work and that is about to change. Even if
    no one is reading this, consider this blog as the first step in accountability
    for the rest of the summer. I will be using this to keep a record of everything I
    am working on day to day.
&lt;/p&gt;
&lt;p&gt; With the exception of this introduction post, every post will attempt to
    keep a focus on a particular issue. I might write a post about a
    topic related to my Summer of Code work, or something related to
    my many other interests. I endeavor to remain positive and
    thoughtful, I will work on my clear overuse of commas, and I will
    try to make my readers laugh.
&lt;/p&gt;
&lt;p&gt; I look forward to keeping this up! JD out. &lt;/p&gt;
</description>
    </item>
  </channel>
</rss>